I thought that reconnectTries: Infinity was relevant but I can reproduce without
it.

The issue happens when the last nextFunction call ends up in the "if we don't
have a cursorId" state.


Looks like

```
calling nextObject
CALLING nextFunction
HERE 2
got error from nextObject: MongoError: connection 2 to c615.lighthouse.4.mongolayer.com:10615 closed
restarting cursor soon
calling nextObject
CALLING nextFunction
!init
cursorId is null
calling _find
got joined primary c615.lighthouse.4.mongolayer.com:10615 => {"setName":"set-59d2c65e61320f48ba000da1","setVersion":4,"ismaster":true,"secondary":false,"hosts":["c615.lighthouse.4.mongolayer.com:10615","c615.lighthouse.5.mongolayer.com:10615"],"primary":"c615.lighthouse.5.mongolayer.com:10615","me":"c615.lighthouse.5.mongolayer.com:10615","electionId":"59d3cd23096f160cb880fcfc","maxBsonObjectSize":16777216,"maxMessageSizeBytes":48000000,"maxWriteBatchSize":1000,"localTime":"2017-10-03T17:47:19.927Z","maxWireVersion":3,"minWireVersion":0,"ok":1}
failing over to c615.lighthouse.5.mongolayer.com:10615
got joined secondary c615.lighthouse.5.mongolayer.com:10615 => {"setName":"set-59d2c65e61320f48ba000da1","setVersion":4,"ismaster":false,"secondary":true,"hosts":["c615.lighthouse.4.mongolayer.com:10615","c615.lighthouse.5.mongolayer.com:10615"],"primary":"c615.lighthouse.5.mongolayer.com:10615","me":"c615.lighthouse.4.mongolayer.com:10615","maxBsonObjectSize":16777216,"maxMessageSizeBytes":48000000,"maxWriteBatchSize":1000,"localTime":"2017-10-03T17:47:20.127Z","maxWireVersion":3,"minWireVersion":0,"ok":1}
```

OK so we have a new cursor, we send the command on the wireProtocolHandler, then
we get stuck in _find.


object{
  servers: [{host, port}]
  auth: {}
  server_options: {socketOptions:{}}
  db_options: {readPreference: "primary", authSource:"asdf", poolSize: 1},
  rs_options: {rs_name: "myset", socketOptions: {}},
  mongos_options: {socketOptions: {}}
}

servers get mapped into Server objecst from mongodb non-core

you have new Db(dbname, new ReplSet(servers, options), options)
then db.open(callback)

replsets have a state on this.s.  its .s.replset points to a Core replset.

Db also has a state on this.s.
the ReplSet (non-core) is the db.s.topology

cursors choose a server with topology.getServer



5 -> 4

!init
got server 5
cursorId is null
calling _find
Pool.write new oplog query (requestId 33)
added as only non-monitoring
however, the connectino is disconnected so we don't pop it.
done executing.

then we write a $cmd ismaster



5 -> 4
got error from nextObject: connection to 5 closed
!init
got server 5
cursorId is null
calling _find
Pool.write new oplog query (requestId 26)
added as only non-monitoring
however, the connectino is disconnected so we don't pop it.
done executing.





5 -> 4

got error from nextObject: connection to 5 closed
!init
got server 5
cursorId is null
calling _find
Pool.write new oplog query (requestId 24)
added as only non-monitoring
however, the connectino is disconnected so we don't pop it.
done executing.


we write ismaster to 4


we learn (probably from the ismaster) that 4 is the primary

on 5, we continue to have no available


we write another ismaster to 4

we get the connectNewServers (CNS on interval) for 5.
we create a brand new 5 queue.
create a new connection

Unfortunately my fix doesn't actually fix it. Need to dig into whether or not
the Server actually gets destroyed.



4->5

5->4
got error from nextObject: closed
we're on pool 3 for 5
write it out



The problem happens when the toplogy still thinks it is connected

Seems to be difference between connection closed and operation interrupted.


OK. If the operation is *just* interrupted, not closed, then it might go forward
immediately and get it from queue into workItems, which is OK.

And if it's closed and we update the repl state to say the server is gone, then
we use the disconnectHandler and it's OK.

The problem is if we see one level of closed (operation is closed) but not another???

if it breaks with "has sockets" I want to see why

Why are there more available with poolSize 1.


THERE ARE TWO COPIES OF THE SAME CONNECTION IN AVAILABLECONNECTIONS




how does this happen

we make a new pool for c615.lighthouse.5.mongolayer.com 3
we make a conn to it (id 3)
we move it to available as part of the Pool.connect
we write ismaster to it. for some reason monitoring is undefined?
we run authenticateStragglers on it which does a no-op inUse -> available


we write another ismaster to it.  this time it is monitoring!
it moves the connection to inUse

somewhere around here we Pool.auth
we clear live connections
then we get the ismaster answer back.  this moves us back into available connections.



theories:

  - authenticateStragglers shouldn't do anything if we're currently authenticating
  - authenticateLiveConnections should actually 
